global:
  storageClass: ""
  
postgresql:
  enabled: true
  fullnameOverride: "omar-ai-postgresql"
  auth:
    username: postgres
    password: postgres
    database: omar-aidb
  service:
    port: 5432
  persistence:
    enabled: true
    size: 10Gi

omar-ai-desktop:
  fullnameOverride: "omar-ai-desktop"
  image:
    repository: ghcr.io/omar-ai-ai/omar-ai-desktop
    tag: edge
  service:
    type: ClusterIP
    port: 9990
  resources:
    limits:
      memory: "4Gi"
      cpu: "2000m"
    requests:
      memory: "2Gi"
      cpu: "1000m"
  shm:
    enabled: true
    size: "2Gi"

omar-ai-agent:
  fullnameOverride: "omar-ai-agent"
  image:
    repository: ghcr.io/omar-ai-ai/omar-ai-agent
    tag: edge
  service:
    type: ClusterIP
    port: 9991
  config:
    omar-aiDesktopUrl: "http://omar-ai-desktop:9990"
  postgresql:
    enabled: false
  externalDatabase:
    host: "omar-ai-postgresql"
    port: 5432
    database: omar-aidb
    username: postgres
    password: postgres
  # Legacy API key configuration (for backward compatibility)
  env:
    ANTHROPIC_API_KEY: ""
    OPENAI_API_KEY: ""
    GEMINI_API_KEY: ""
  
  # New secret management structure - use this for better security
  apiKeys:
    anthropic:
      useExisting: false
      secretName: ""
      secretKey: "anthropic-api-key"
      value: ""  # Only used if useExisting is false
    openai:
      useExisting: false
      secretName: ""
      secretKey: "openai-api-key"
      value: ""  # Only used if useExisting is false
    gemini:
      useExisting: false
      secretName: ""
      secretKey: "gemini-api-key"
      value: ""  # Only used if useExisting is false
  resources:
    limits:
      memory: "2Gi"
      cpu: "1000m"
    requests:
      memory: "1Gi"
      cpu: "500m"

omar-ai-ui:
  fullnameOverride: "omar-ai-ui"
  image:
    repository: ghcr.io/omar-ai-ai/omar-ai-ui
    tag: edge
  service:
    type: ClusterIP
    port: 9992
  config:
    agentBaseUrl: "http://omar-ai-agent:9991"
    desktopVncUrl: "http://omar-ai-desktop:9990/websockify"
  resources:
    limits:
      memory: "1Gi"
      cpu: "500m"
    requests:
      memory: "512Mi"
      cpu: "250m"

# LiteLLM proxy is disabled by default
# Enable it by using -f values-proxy.yaml or --set omar-ai-llm-proxy.enabled=true
omar-ai-llm-proxy:
  enabled: false

ingress:
  enabled: false
  className: "nginx"
  annotations:
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
  host: omar-ai.example.com
  tls:
    enabled: true
    secretName: omar-ai-tls